#!/usr/bin/env ruby
require "timeout"
require "net/http"
require "uri"
#
# MAC Age Tracker
#
@macs  = {}
@today = Time.now.strftime("%Y-%m-%d")
@based = File.expand_path(File.dirname(__FILE__))

Dir.chdir(@based)

def update(addr, date, source)
	if ! @macs[addr]
		@macs[addr] = [date, source]
		return
	end

	odate = @macs[addr].first.gsub("-", "").to_i
	ndate = date.gsub("-", "").to_i

	# Overwrite if new record is older
	if ndate < odate
		@macs[addr] = [date, source]
	end
end

def load_current
	File.readlines(File.join(@based, "data", "mac-ages.csv")).each do |raw|
		bits = raw.strip.split(",", 3)
		if bits[0].index("/").nil?
			bits[0] << "/24"
		end

		addr_base,addr_mask = bits[0].downcase.split("/")
		addr_base = mac_pad(addr_base)

		date = bits[1]
		src  = bits[2]

		update(addr_base + "/" + addr_mask, date, src)
	end
end

def mac_pad(addr)
	addr.ljust(12, "0")
end

def load_ieee_urls
	ieee_urls =  [
		["https://standards-oui.ieee.org/oui/oui.csv", 29227],
		["https://standards-oui.ieee.org/cid/cid.csv", 115], 
		["https://standards-oui.ieee.org/iab/iab.csv", 4576],
		["https://standards-oui.ieee.org/oui28/mam.csv", 3484],
		["https://standards-oui.ieee.org/oui36/oui36.csv", 4154],
    ]
    ieee_urls.each do |url_info|
    	url_path, url_min_records = url_info
    	Timeout.timeout(300) do 
    		records = download_ieee(url_path)
		if records.nil?
    			raise RuntimeError, "URL #{url_path} returned zero records (wanted >= #{url_min_records})"
    		end
    		if records.length < url_min_records
    			raise RuntimeError, "URL #{url_path} only has #{records.length} records (wanted >= #{url_min_records})"
    		end
    		records.each do |rec|
    			next if rec =~ /^Registry,/
    			info = rec.split(",", 3)
    			addr_base = info[1]
			if addr_base.nil?
				$stderr.puts "URL #{url_path} has bad line: #{rec}"
				next
			end
    			addr_mask = ((addr_base.length / 2.0) * 8).to_i
				addr_base = mac_pad(addr_base)
    			addr = "#{addr_base}/#{addr_mask}".downcase
    			update(addr, @today, "ieee-#{File.basename(url_path)}")
    		end
    	end
    end
end

def download_ieee(url)
	name = File.basename(url)
	path = File.join(@based, "data", "ieee", name)

	retries = 0 
	begin
		data = Net::HTTP.get(URI(url))
	rescue ::Timeout, ::Interrupt
		raise $!
	rescue ::Exception
		if retries > 5
			raise $1
		end
		retries += 1
		sleep(5)
		retry
	end

	File.open(path, "wb") do |fd|
		fd.write(data)
	end
	data.split("\n").map{|x| x.strip}
end

def sortable_prefix(str)
	prefix, mask = str.split("/")
	mask = mask.rjust(2, "0")
	mask + prefix
end

def write_results
	fd = File.open(File.join(@based, "data", "mac-ages.csv"), "wb")
	@macs.keys.sort{|a,b| sortable_prefix(b) <=> sortable_prefix(a) }.
		each do |mac|
		fd.puts [mac, @macs[mac][0], @macs[mac][1]].join(",")
	end
	fd.close
end

def log(msg)
	$stdout.puts "#{Time.now.to_s} #{msg}"
	$stdout.flush
end

log("Starting update for #{@today.to_s}")

# Sources
log("Loading current dataset")
load_current()

log("Loading the IEEE URLs")
old_count = @macs.keys.length 
load_ieee_urls()
new_count = @macs.keys.length 

# Generate merged output
log("Writing results for #{@macs.keys.length} entries (#{old_count} -> #{new_count})")
write_results()

log("Commiting and pushing the results")

# Commit the results
r = system("git commit -m 'Update #{@today}' ./data && git push origin main")
if ! r
  log("Commit failed: #{r}")
  exit(1)
end
exit(0)

